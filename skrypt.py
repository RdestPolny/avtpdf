import streamlit as st
import fitz  # PyMuPDF
import openai
import os
import io
import zipfile
import json
from pathlib import Path
import re
import asyncio
from openai import AsyncOpenAI

# --- Konfiguracja strony ---
st.set_page_config(
    layout="wide",
    page_title="Redaktor AI - Procesor PDF",
    page_icon="üöÄ"
)

# --- Style CSS dla nowoczesnego wyglƒÖdu ---
st.markdown("""
<style>
    .stApp { 
        background-color: #F0F2F5; 
        font-family: 'Segoe UI', sans-serif; 
    }
    .main > div { 
        background-color: #FFFFFF; 
        padding: 2rem; 
        border-radius: 15px; 
        box-shadow: 0 8px 32px 0 rgba(0, 0, 0, 0.1); 
    }
    .stButton>button { 
        border-radius: 8px; 
        border: 1px solid #E0E0E0; 
        color: #333333; 
        background-color: #FFFFFF; 
        transition: all 0.2s ease-in-out; 
        padding: 0.5rem 1rem; 
    }
    .stButton>button:hover { 
        border-color: #007BFF; 
        color: #007BFF; 
        box-shadow: 0 2px 5px 0 rgba(0, 123, 255, 0.2); 
    }
    .stButton[data-testid="stButton-ProcessAI"] button { 
        background-color: #007BFF; 
        color: white; 
        font-weight: bold; 
    }
    .page-text-wrapper { 
        padding: 1.5rem; 
        border-radius: 8px; 
        border: 1px solid #E8E8E8; 
        background-color: #FAFAFA; 
        min-height: 500px;
        max-height: 600px;
        overflow-y: auto;
    }
    .page-text-wrapper h4 { 
        color: #007BFF; 
        border-bottom: 2px solid #007BFF; 
        padding-bottom: 8px; 
        margin-bottom: 1rem; 
    }
    .stMetric {
        text-align: center;
    }
    .error-box {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        color: #721c24;
        padding: 1rem;
        border-radius: 8px;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# --- ZarzƒÖdzanie stanem sesji ---
def init_session_state():
    defaults = {
        'processing_status': 'idle', 'pdf_doc': None, 'current_page': 0,
        'total_pages': 0, 'extracted_pages': [], 'project_name': None,
        'next_batch_start_index': 0, 'uploaded_filename': None,
        'api_key': os.environ.get("OPENAI_API_KEY", ""), 
        'model': 'gpt-4o-mini',  # ZMIANA: Ustawienie nowego domy≈õlnego modelu
        'meta_tags': {}
    }
    for key, value in defaults.items():
        if key not in st.session_state: st.session_state[key] = value

init_session_state()

# --- Funkcje Pomocnicze ---
PROJECTS_DIR = Path("pdf_processor_projects")
BATCH_SIZE = 10
MAX_RETRIES = 2

def ensure_projects_dir():
    try:
        PROJECTS_DIR.mkdir(exist_ok=True); return True
    except Exception as e:
        st.error(f"Nie mo≈ºna utworzyƒá katalogu projekt√≥w: {e}"); return False

def get_existing_projects():
    if not ensure_projects_dir(): return []
    return [d.name for d in PROJECTS_DIR.iterdir() if d.is_dir()]

def sanitize_filename(name):
    if not name: return "unnamed_project"
    sanitized = re.sub(r'[\\/*?:"<>|]', "_", str(name))
    return re.sub(r'_{2,}', "_", sanitized).strip("_") or "unnamed_project"

def render_page_as_image(pdf_doc, page_num):
    try:
        if not pdf_doc or not (0 <= page_num < len(pdf_doc)): return None
        page = pdf_doc.load_page(page_num); pix = page.get_pixmap(matrix=fitz.Matrix(2.0, 2.0))
        return pix.tobytes("png")
    except Exception as e:
        st.error(f"B≈ÇƒÖd podczas renderowania strony {page_num + 1}: {e}"); return None

def extract_images_from_page(pdf_doc, page_num):
    images = []
    if not pdf_doc or not (0 <= page_num < len(pdf_doc)): return images
    try:
        page = pdf_doc.load_page(page_num)
        for img_index, img in enumerate(page.get_images(full=True)):
            xref = img[0]; base_image = pdf_doc.extract_image(xref)
            if base_image and base_image.get("width", 0) > 100 and base_image.get("height", 0) > 100:
                images.append({'image': base_image['image'], 'ext': base_image['ext'], 'index': img_index})
    except Exception as e:
        st.warning(f"Nie uda≈Ço siƒô wyekstraktowaƒá obraz√≥w ze strony {page_num + 1}: {e}")
    return images

def create_zip_archive(data, file_prefix="item"):
    zip_buffer = io.BytesIO()
    with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
        for item in data: zf.writestr(item['name'], item['content'])
    return zip_buffer.getvalue()

def save_project():
    if not st.session_state.project_name or not ensure_projects_dir():
        st.error("Nie mo≈ºna zapisaƒá projektu: brak nazwy projektu."); return
    project_path = PROJECTS_DIR / st.session_state.project_name; project_path.mkdir(exist_ok=True)
    state_to_save = {k: v for k, v in st.session_state.items() if k not in ['pdf_doc']}
    state_to_save['extracted_pages'] = [p for p in st.session_state.extracted_pages if p is not None]
    try:
        with open(project_path / "project_state.json", "w", encoding="utf-8") as f:
            json.dump(state_to_save, f, indent=2, ensure_ascii=False)
        st.toast(f"‚úÖ Projekt '{st.session_state.project_name}' zosta≈Ç zapisany!", icon="üíæ")
    except Exception as e:
        st.error(f"B≈ÇƒÖd podczas zapisywania projektu: {e}")

def load_project(project_name):
    project_file = PROJECTS_DIR / project_name / "project_state.json"
    if not project_file.exists(): st.error(f"Plik projektu '{project_name}' nie istnieje."); return
    try:
        with open(project_file, "r", encoding="utf-8") as f: state_to_load = json.load(f)
        for key, value in state_to_load.items():
            if key != 'pdf_doc': st.session_state[key] = value
        total_pages = st.session_state.get('total_pages', 0)
        st.session_state.extracted_pages = [None] * total_pages
        for page_data in state_to_load.get('extracted_pages', []):
            page_num_one_based = page_data.get('page_number')
            if page_num_one_based and 1 <= page_num_one_based <= total_pages:
                st.session_state.extracted_pages[page_num_one_based - 1] = page_data
        st.success(f"‚úÖ Za≈Çadowano projekt '{project_name}'. Wgraj powiƒÖzany plik PDF, aby kontynuowaƒá.")
        st.session_state.pdf_doc = None
    except Exception as e:
        st.error(f"B≈ÇƒÖd podczas ≈Çadowania projektu: {e}")

# --- Funkcje Przetwarzania AI ---
def markdown_to_html(text):
    text = text.replace('\n---\n', '\n<hr>\n')
    text = re.sub(r'^\s*# (.*?)\s*$', r'<h2>\1</h2>', text, flags=re.MULTILINE)
    text = re.sub(r'^\s*## (.*?)\s*$', r'<h3>\1</h3>', text, flags=re.MULTILINE)
    text = re.sub(r'^\s*### (.*?)\s*$', r'<h4>\1</h4>', text, flags=re.MULTILINE)
    text = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', text)
    paragraphs = text.split('\n\n')
    html_content = []
    for para in paragraphs:
        para = para.strip()
        if not para: continue
        if para.startswith(('<h', '<hr')): html_content.append(para)
        else: html_content.append(f"<p>{para.replace(chr(10), '<br>')}</p>")
    return ''.join(html_content)

async def process_page_async(client, page_num, raw_text, model):
    page_data = {"page_number": page_num}

    if len(raw_text.split()) < 20:
        page_data["type"] = "pominiƒôta"; page_data["formatted_content"] = "<i>Strona zawiera zbyt ma≈Ço tekstu.</i>"
        return page_data

    prompt = f"""Jeste≈õ precyzyjnym asystentem redakcyjnym. Twoim celem jest przekszta≈Çcenie surowego tekstu w czytelny, dobrze zorganizowany artyku≈Ç internetowy.

ZASADA NADRZƒòDNA: WIERNO≈öƒÜ TRE≈öCI, ELASTYCZNO≈öƒÜ FORMY
- **Nie zmieniaj oryginalnych sformu≈Çowa≈Ñ ani nie parafrazuj tekstu.** Twoim zadaniem jest przenie≈õƒá tre≈õƒá 1:1.
- Twoja rola polega na **dodawaniu element√≥w strukturalnych** (nag≈Ç√≥wki, pogrubienia, podzia≈Ç na akapity) w celu poprawy czytelno≈õci.

INSTRUKCJE SPECJALNE: Oczyszczanie i Kontekst
1.  **Ignorowanie Szumu**: Musisz zidentyfikowaƒá i ca≈Çkowicie pominƒÖƒá w finalnym tek≈õcie nastƒôpujƒÖce elementy, je≈õli wystƒôpujƒÖ na poczƒÖtku lub ko≈Ñcu:
    - Numery stron (np. "6", "12").
    - Rozstrzelone daty (np. "c z e r w i e c  2 0 2 5").
2.  **Wykorzystanie Kategorii**:
    - Na poczƒÖtku tekstu mo≈ºesz znale≈∫ƒá etykietƒô, np. "od redakcji", "NEWS FLASH", "WYWIAD MIESIƒÑCA".
    - U≈ºyj tej etykiety jako **kontekstu** do zrozumienia intencji tekstu, ale **nie umieszczaj jej w sformatowanym artykule**.

DOZWOLONE MODYFIKACJE STRUKTURALNE:
1.  **Tytu≈Ç G≈Ç√≥wny (`# Tytu≈Ç`)**:
    - **ZNAJD≈π go w tek≈õcie**. To czƒôsto kr√≥tka linia bez kropki na ko≈Ñcu.
    - **Absolutny zakaz** wymy≈õlania tytu≈Ç√≥w. Je≈õli go nie ma, nie dodawaj go.
2.  **≈ör√≥dtytu≈Çy (`## ≈ör√≥dtytu≈Ç`) - Tw√≥j kluczowy obowiƒÖzek**:
    - Celem jest przekszta≈Çcenie '≈õciany tekstu' w czytelny artyku≈Ç.
    - Gdy tekst zawiera kilka nastƒôpujƒÖcych po sobie akapit√≥w omawiajƒÖcych r√≥≈ºne przyk≈Çady, technologie lub firmy, **MUSISZ** je rozdzieliƒá trafnymi, zwiƒôz≈Çymi ≈õr√≥dtytu≈Çami.
3.  **Pogrubienia (`**tekst**`)**:
    - Stosuj je, by wyr√≥≈ºniƒá **kluczowe terminy, nazwy w≈Çasne i frazy wa≈ºne dla SEO**.
    - W d≈Çu≈ºszych akapitach pogrub **jedno kluczowe zdanie lub wniosek**, aby u≈Çatwiƒá szybkie czytanie.
4.  **Podzia≈Ç na sekcje**:
     - Je≈õli tekst na stronie wyra≈∫nie zawiera **dwa lub wiƒôcej niepowiƒÖzanych ze sobƒÖ temat√≥w**, oddziel je liniƒÖ horyzontalnƒÖ (`---`).

WYMAGANIA KRYTYCZNE:
- Twoja odpowied≈∫ musi byƒá **WY≈ÅƒÑCZNIE i BEZWZGLƒòDNIE** poprawnym obiektem JSON.

FORMAT ODPOWIEDZI:
{{"type": "ARTYKU≈Å" lub "REKLAMA", "formatted_text": "Sformatowany tekst w markdown. Je≈õli jest wiele artyku≈Ç√≥w, oddziel je '---'."}}

TEKST DO PRZETWORZENIA:
---
{raw_text}
---
"""
    last_error = None
    for attempt in range(MAX_RETRIES + 1):
        content = ""
        try:
            # ZMIANA: Inteligentny prze≈ÇƒÖcznik API w zale≈ºno≈õci od modelu
            if "gpt-5" in model:
                response = await client.responses.create(
                    model=model, input=prompt,
                    reasoning={"effort": "low"}, text={"verbosity": "low"},
                )
                content = response.output_text
            else: # Domy≈õlne dla GPT-4o, GPT-4, etc.
                response = await client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": prompt}],
                    response_format={"type": "json_object"},
                    temperature=0.1,
                    max_tokens=2048
                )
                content = response.choices[0].message.content

            if not content: raise ValueError("API zwr√≥ci≈Ço pustƒÖ odpowied≈∫.")
            json_match = re.search(r'\{.*\}', content, re.DOTALL)
            if not json_match: raise ValueError("W odpowiedzi AI nie znaleziono obiektu JSON.")
            clean_content = json_match.group(0)
            ai_result = json.loads(clean_content)
            page_data["type"] = ai_result.get("type", "nieznany").lower()
            formatted_text = ai_result.get("formatted_text", "")
            if page_data["type"] == "artyku≈Ç":
                page_data["formatted_content"] = markdown_to_html(formatted_text)
                page_data["raw_markdown"] = formatted_text
            else:
                page_data["formatted_content"] = f"<i>Zidentyfikowano jako: <strong>{page_data['type'].upper()}</strong>.</i>"
            return page_data
        except (json.JSONDecodeError, ValueError) as e:
            last_error = e
            if attempt < MAX_RETRIES: await asyncio.sleep(1)
            continue
        except Exception as e:
            last_error = e; break
    page_data["type"] = "b≈ÇƒÖd"
    page_data["formatted_content"] = f"""
    <div class="error-box"><strong>B≈ÇƒÖd parsowania po {MAX_RETRIES + 1} pr√≥bach.</strong><br><i>Ostatni b≈ÇƒÖd: {last_error}</i><br>
    <details><summary>Poka≈º ostatniƒÖ surowƒÖ odpowied≈∫</summary><pre>{content or "Brak odpowiedzi"}</pre></details></div>"""
    return page_data

async def generate_meta_tags_async(client, article_text, model):
    prompt = f"""Jeste≈õ ekspertem SEO. Na podstawie poni≈ºszego tekstu artyku≈Çu, wygeneruj chwytliwy meta title i zwiƒôz≈Çy meta description.
WYMAGANIA:
- Meta title: max 60 znak√≥w.
- Meta description: max 160 znak√≥w.
- Odpowied≈∫ zwr√≥ƒá jako obiekt JSON.
FORMAT ODPOWIEDZI:
{{"meta_title": "Tytu≈Ç meta", "meta_description": "Opis meta."}}
TEKST ARTYKU≈ÅU:
---
{article_text[:4000]}
---
"""
    last_error = None
    for attempt in range(MAX_RETRIES + 1):
        content = ""
        try:
            # ZMIANA: Inteligentny prze≈ÇƒÖcznik API w zale≈ºno≈õci od modelu
            if "gpt-5" in model:
                response = await client.responses.create(
                    model=model, input=prompt,
                    reasoning={"effort": "low"}, text={"verbosity": "low"},
                )
                content = response.output_text
            else:
                response = await client.chat.completions.create(
                    model=model,
                    messages=[{"role": "user", "content": prompt}],
                    response_format={"type": "json_object"},
                    temperature=0.5,
                    max_tokens=200
                )
                content = response.choices[0].message.content

            if not content: raise ValueError("API zwr√≥ci≈Ço pustƒÖ odpowied≈∫.")
            return json.loads(content)
        except (json.JSONDecodeError, ValueError) as e:
            last_error = e
            if attempt < MAX_RETRIES: await asyncio.sleep(1)
            continue
        except Exception as e:
            return {"error": str(e)}
    return {"error": f"B≈ÇƒÖd parsowania po {MAX_RETRIES + 1} pr√≥bach. Odpowied≈∫: '{content}'"}

async def process_batch(start_index):
    client = AsyncOpenAI(api_key=st.session_state.api_key)
    end_index = min(start_index + BATCH_SIZE, st.session_state.total_pages)
    tasks = [process_page_async(client, i + 1, st.session_state.pdf_doc.load_page(i).get_text("text"), st.session_state.model) for i in range(start_index, end_index) if st.session_state.pdf_doc]
    results = await asyncio.gather(*tasks, return_exceptions=True)
    for i, result in enumerate(results):
        page_index = start_index + i
        if isinstance(result, Exception):
            st.session_state.extracted_pages[page_index] = {"page_number": page_index + 1, "type": "b≈ÇƒÖd", "formatted_content": f"B≈ÇƒÖd: {result}"}
        else:
            st.session_state.extracted_pages[page_index] = result

def render_sidebar():
    with st.sidebar:
        st.header("‚öôÔ∏è Konfiguracja Projektu")
        st.subheader("üìÇ Projekt")
        projects = get_existing_projects()
        selected_project = st.selectbox("Wybierz istniejƒÖcy projekt", ["Nowy projekt"] + projects)
        if st.button("Za≈Çaduj projekt", disabled=(selected_project == "Nowy projekt")):
            load_project(selected_project); st.rerun()
        st.divider()
        st.subheader("üìÑ Plik PDF")
        uploaded_file = st.file_uploader("Wybierz plik PDF", type="pdf")
        if uploaded_file and uploaded_file.name != st.session_state.uploaded_filename:
            handle_file_upload(uploaded_file)
        st.divider()
        st.subheader("ü§ñ Konfiguracja AI")
        st.session_state.api_key = st.text_input("Klucz API OpenAI", type="password", value=st.session_state.api_key)
        
        # ZMIANA: Zaktualizowana lista modeli z gpt-4o-mini na poczƒÖtku
        st.session_state.model = st.selectbox(
            "Model AI", 
            ["gpt-4o-mini", "gpt-4o", "gpt-5-nano", "gpt-5-mini", "gpt-5"], 
            index=0
        )
        
        if st.session_state.pdf_doc:
            st.divider()
            processing_disabled = st.session_state.processing_status == 'in_progress' or not st.session_state.api_key
            button_text = "üîÑ Przetwarzanie..." if st.session_state.processing_status == 'in_progress' else "üöÄ Rozpocznij Przetwarzanie"
            if st.button(button_text, use_container_width=True, type="primary", disabled=processing_disabled, key="stButton-ProcessAI"):
                start_ai_processing(); st.rerun()
        
        if st.session_state.project_name:
            st.divider(); st.info(f"**Projekt:** `{st.session_state.project_name}`"); st.metric("Liczba stron", st.session_state.total_pages)

def handle_file_upload(uploaded_file):
    try:
        with st.spinner("≈Åadowanie pliku PDF..."):
            pdf_doc = fitz.open(stream=uploaded_file.read(), filetype="pdf")
            st.session_state.pdf_doc = pdf_doc; st.session_state.uploaded_filename = uploaded_file.name
            st.session_state.project_name = sanitize_filename(Path(uploaded_file.name).stem)
            st.session_state.total_pages = len(pdf_doc); st.session_state.current_page = 0
            st.session_state.extracted_pages = [None] * len(pdf_doc); st.session_state.processing_status = 'idle'
            st.session_state.next_batch_start_index = 0; st.session_state.meta_tags = {}
    except Exception as e:
        st.error(f"‚ùå B≈ÇƒÖd ≈Çadowania pliku: {e}"); st.session_state.pdf_doc = None
    st.rerun()

def start_ai_processing():
    if not st.session_state.api_key: st.error("‚ö†Ô∏è Proszƒô podaƒá klucz API OpenAI."); return
    st.session_state.processing_status = 'in_progress'; st.session_state.next_batch_start_index = 0
    st.session_state.extracted_pages = [None] * st.session_state.total_pages

def render_processing_status():
    if st.session_state.processing_status == 'idle': return
    processed_count = sum(1 for p in st.session_state.extracted_pages if p is not None)
    progress = processed_count / st.session_state.total_pages if st.session_state.total_pages > 0 else 0
    
    if st.session_state.processing_status == 'complete': st.success(f"‚úÖ Przetwarzanie zako≈Ñczone!")
    else: st.info(f"üîÑ Przetwarzanie w toku... ({processed_count}/{st.session_state.total_pages})"); st.progress(progress)
    
    c1, c2, _ = st.columns([1, 1, 3])
    if c1.button("üíæ Zapisz postƒôp", use_container_width=True): save_project()
    articles = [p for p in st.session_state.extracted_pages if p and p.get('type') == 'artyku≈Ç']
    if articles:
        zip_data = [{'name': f"strona_{a['page_number']}.txt", 'content': a['raw_markdown'].encode('utf-8')} for a in articles if 'raw_markdown' in a]
        if zip_data: c2.download_button("üì• Pobierz artyku≈Çy", create_zip_archive(zip_data), f"{st.session_state.project_name}_artykuly.zip", "application/zip", use_container_width=True)

def render_navigation():
    if st.session_state.total_pages <= 1: return
    st.subheader("üìñ Nawigacja")
    c1, c2, c3 = st.columns([1, 2, 1])
    if c1.button("‚¨ÖÔ∏è Poprzednia", use_container_width=True, disabled=(st.session_state.current_page == 0)): st.session_state.current_page -= 1; st.rerun()
    c2.metric("Strona", f"{st.session_state.current_page + 1} / {st.session_state.total_pages}")
    if c3.button("Nastƒôpna ‚û°Ô∏è", use_container_width=True, disabled=(st.session_state.current_page >= st.session_state.total_pages - 1)): st.session_state.current_page += 1; st.rerun()
    
    new_page = st.slider("Przejd≈∫ do strony:", 1, st.session_state.total_pages, st.session_state.current_page + 1) - 1
    if new_page != st.session_state.current_page: st.session_state.current_page = new_page; st.rerun()

def render_page_content():
    st.divider()
    pdf_col, text_col = st.columns(2, gap="large")
    page_index = st.session_state.current_page

    with pdf_col:
        st.subheader(f"üìÑ Orygina≈Ç (Strona {page_index + 1})")
        image_data = render_page_as_image(st.session_state.pdf_doc, page_index)
        if image_data:
            st.image(image_data, use_container_width=True)
            images = extract_images_from_page(st.session_state.pdf_doc, page_index)
            if images:
                with st.expander(f"üñºÔ∏è Poka≈º/ukryj {len(images)} obraz(y) z tej strony"):
                    for img in images: st.image(img['image'], caption=f"Obraz {img['index'] + 1}", use_container_width=True)
                img_zip = create_zip_archive([{'name': f"str_{page_index+1}_img_{i['index']}.{i['ext']}", 'content': i['image']} for i in images])
                st.download_button("Pobierz obrazy", img_zip, f"obrazy_strona_{page_index+1}.zip", "application/zip", use_container_width=True)
        else: st.error("Nie mo≈ºna wy≈õwietliƒá podglƒÖdu strony.")

    with text_col:
        st.subheader("ü§ñ Tekst przetworzony przez AI")
        
        raw_text = st.session_state.pdf_doc.load_page(page_index).get_text("text")
        with st.expander("üëÅÔ∏è Poka≈º surowy tekst wej≈õciowy z tej strony"):
            st.text_area("Surowy tekst", raw_text, height=200, disabled=True, key=f"raw_text_{page_index}")
        
        page_result = st.session_state.extracted_pages[page_index]
        if page_result:
            page_type = page_result.get('type', 'nieznany')
            color = {"artyku≈Ç": "green", "reklama": "orange", "pominiƒôta": "grey"}.get(page_type, "red")
            st.markdown(f"**Status:** <span style='color:{color}; text-transform:uppercase;'>**{page_type}**</span>", unsafe_allow_html=True)
            st.markdown(f"<div class='page-text-wrapper'>{page_result.get('formatted_content', '')}</div>", unsafe_allow_html=True)
            action_cols = st.columns(2)
            if action_cols[0].button("üîÑ Przetw√≥rz ponownie (z kontekstem)", key=f"reroll_{page_index}", use_container_width=True):
                with st.spinner("Przetwarzanie strony z kontekstem..."):
                    prev_text = st.session_state.pdf_doc.load_page(page_index - 1).get_text("text") if page_index > 0 else ""
                    curr_text = st.session_state.pdf_doc.load_page(page_index).get_text("text")
                    next_text = st.session_state.pdf_doc.load_page(page_index + 1).get_text("text") if page_index < st.session_state.total_pages - 1 else ""
                    context_text = (f"KONTEKST (POPRZEDNIA STRONA):\n{prev_text}\n\n--- STRONA DOCELOWA ---\n{curr_text}\n\nKONTEKST (NASTƒòPNA STRONA):\n{next_text}")
                    client = AsyncOpenAI(api_key=st.session_state.api_key)
                    new_result = asyncio.run(process_page_async(client, page_index + 1, context_text, st.session_state.model))
                    st.session_state.extracted_pages[page_index] = new_result
                st.rerun()
            if page_type == 'artyku≈Ç' and 'raw_markdown' in page_result:
                 if action_cols[1].button("‚ú® SEO: Generuj Meta Tagi", key=f"meta_{page_index}", use_container_width=True):
                    with st.spinner("Generowanie meta tag√≥w..."):
                        client = AsyncOpenAI(api_key=st.session_state.api_key)
                        tags = asyncio.run(generate_meta_tags_async(client, page_result['raw_markdown'], st.session_state.model))
                        st.session_state.meta_tags[page_index] = tags
                    st.rerun()
            if page_index in st.session_state.meta_tags:
                tags = st.session_state.meta_tags[page_index]
                if "error" in tags: st.error(f"B≈ÇƒÖd generowania meta tag√≥w: {tags['error']}")
                else:
                    with st.expander("Wygenerowane Meta Tagi ‚ú®", expanded=True):
                        st.text_input("Meta Title", value=tags.get("meta_title", ""), key=f"mt_{page_index}")
                        st.text_area("Meta Description", value=tags.get("meta_description", ""), key=f"md_{page_index}")
        else:
            st.info("‚è≥ Strona oczekuje na przetworzenie..." if st.session_state.processing_status == 'in_progress' else "Uruchom przetwarzanie w panelu bocznym.")

def main():
    st.title("üöÄ Redaktor AI - Interaktywny Procesor PDF")
    render_sidebar()
    if not st.session_state.pdf_doc:
        st.info("üëã Witaj! Aby rozpoczƒÖƒá, wgraj plik PDF lub za≈Çaduj istniejƒÖcy projekt z panelu bocznego."); return
    render_processing_status()
    if st.session_state.processing_status == 'in_progress' and st.session_state.next_batch_start_index < st.session_state.total_pages:
        asyncio.run(process_batch(st.session_state.next_batch_start_index))
        st.session_state.next_batch_start_index += BATCH_SIZE; st.rerun()
    elif st.session_state.processing_status == 'in_progress':
        st.session_state.processing_status = 'complete'; st.rerun()
    render_navigation(); render_page_content()

if __name__ == "__main__":
    main()
