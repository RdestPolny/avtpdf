"""
Redaktor AI - Interaktywny Procesor DokumentÃ³w
===============================================

INSTALACJA ZALEÅ»NOÅšCI:
----------------------
pip uninstall docx  # WAÅ»NE: UsuÅ„ zÅ‚Ä… bibliotekÄ™ jeÅ›li jest zainstalowana!
pip install streamlit PyMuPDF openai python-docx mammoth

MINIMALNA KONFIGURACJA (tylko PDF):
pip install streamlit PyMuPDF openai

URUCHOMIENIE:
streamlit run skrypt.py
"""

import streamlit as st
import fitz  # PyMuPDF
from openai import AsyncOpenAI
import io
import zipfile
import json
from pathlib import Path
import re
import asyncio
from typing import List, Dict, Optional
from dataclasses import dataclass

# Opcjonalne importy - aplikacja bÄ™dzie dziaÅ‚aÄ‡ bez nich (tylko PDF)
try:
    from docx import Document as DocxDocument
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False

try:
    import mammoth
    MAMMOTH_AVAILABLE = True
except ImportError:
    MAMMOTH_AVAILABLE = False

# ===== KONFIGURACJA =====

PROJECTS_DIR = Path("pdf_processor_projects")
BATCH_SIZE = 10
MAX_RETRIES = 3
DEFAULT_MODEL = 'gpt-4o-mini'

SESSION_STATE_DEFAULTS = {
    'processing_status': 'idle',
    'document': None,
    'current_page': 0,
    'total_pages': 0,
    'extracted_pages': [],
    'project_name': None,
    'next_batch_start_index': 0,
    'uploaded_filename': None,
    'api_key': None,
    'model': DEFAULT_MODEL,
    'meta_tags': {},
    'seo_articles': {},
    'project_loaded_and_waiting_for_file': False,
    'processing_mode': 'all',
    'start_page': 1,
    'end_page': 1,
    'processing_end_page_index': 0,
    'article_page_groups_input': '',
    'article_groups': [],
    'next_article_index': 0,
    'file_type': None
}

# ===== KLASY POMOCNICZE =====

@dataclass
class PageContent:
    """Reprezentuje zawartoÅ›Ä‡ pojedynczej strony"""
    page_number: int
    text: str
    images: List[Dict] = None
    
    def __post_init__(self):
        if self.images is None:
            self.images = []

class DocumentHandler:
    """Klasa do obsÅ‚ugi rÃ³Å¼nych formatÃ³w dokumentÃ³w"""
    
    def __init__(self, file_bytes: bytes, filename: str):
        self.file_bytes = file_bytes
        self.filename = filename
        self.file_type = self._detect_file_type(filename)
        self._document = None
        self._html_content = None
        self._load_document()
    
    def _detect_file_type(self, filename: str) -> str:
        ext = Path(filename).suffix.lower()
        if ext == '.pdf':
            return 'pdf'
        elif ext == '.docx':
            if not DOCX_AVAILABLE:
                raise ValueError("Format DOCX nie jest obsÅ‚ugiwany. Zainstaluj: pip install python-docx")
            return 'docx'
        elif ext == '.doc':
            if not MAMMOTH_AVAILABLE:
                raise ValueError("Format DOC nie jest obsÅ‚ugiwany. Zainstaluj: pip install mammoth")
            return 'doc'
        else:
            raise ValueError(f"NieobsÅ‚ugiwany format pliku: {ext}")
    
    def _load_document(self):
        """Åaduje dokument w odpowiednim formacie"""
        if self.file_type == 'pdf':
            self._document = fitz.open(stream=self.file_bytes, filetype="pdf")
        elif self.file_type == 'docx':
            self._document = DocxDocument(io.BytesIO(self.file_bytes))
        elif self.file_type == 'doc':
            result = mammoth.convert_to_html(io.BytesIO(self.file_bytes))
            self._html_content = result.value
            self._document = None
    
    def get_page_count(self) -> int:
        """Zwraca liczbÄ™ stron w dokumencie"""
        if self.file_type == 'pdf':
            return len(self._document)
        elif self.file_type == 'docx':
            all_text = '\n\n'.join([p.text for p in self._document.paragraphs])
            words = all_text.split()
            return max(1, len(words) // 500 + (1 if len(words) % 500 > 0 else 0))
        elif self.file_type == 'doc':
            words = self._html_content.split()
            return max(1, len(words) // 500 + (1 if len(words) % 500 > 0 else 0))
        return 0
    
    def get_page_content(self, page_index: int) -> PageContent:
        """Zwraca zawartoÅ›Ä‡ pojedynczej strony"""
        if self.file_type == 'pdf':
            page = self._document.load_page(page_index)
            text = page.get_text("text")
            images = self._extract_images_from_pdf_page(page_index)
            return PageContent(page_index + 1, text, images)
        elif self.file_type == 'docx':
            return self._get_docx_page_content(page_index)
        elif self.file_type == 'doc':
            return self._get_doc_page_content(page_index)
    
    def _get_docx_page_content(self, page_index: int) -> PageContent:
        """Pobiera zawartoÅ›Ä‡ z DOCX - dzieli na fragmenty"""
        all_paragraphs = self._document.paragraphs
        words_per_page = 500
        
        all_text = '\n\n'.join([p.text for p in all_paragraphs])
        words = all_text.split()
        
        start_word = page_index * words_per_page
        end_word = min(start_word + words_per_page, len(words))
        
        page_text = ' '.join(words[start_word:end_word])
        images = self._extract_images_from_docx()
        
        return PageContent(page_index + 1, page_text, images)
    
    def _get_doc_page_content(self, page_index: int) -> PageContent:
        """Pobiera zawartoÅ›Ä‡ z DOC (HTML)"""
        text = re.sub('<[^<]+?>', '', self._html_content)
        words = text.split()
        words_per_page = 500
        
        start_word = page_index * words_per_page
        end_word = min(start_word + words_per_page, len(words))
        
        page_text = ' '.join(words[start_word:end_word])
        
        return PageContent(page_index + 1, page_text, [])
    
    def _extract_images_from_pdf_page(self, page_index: int) -> List[Dict]:
        """WyciÄ…ga obrazy z strony PDF"""
        images = []
        if self.file_type != 'pdf':
            return images
        
        try:
            page = self._document.load_page(page_index)
            for img_index, img in enumerate(page.get_images(full=True)):
                xref = img[0]
                base_image = self._document.extract_image(xref)
                if base_image and base_image.get("width", 0) > 100 and base_image.get("height", 0) > 100:
                    images.append({
                        'image': base_image['image'],
                        'ext': base_image['ext'],
                        'index': img_index
                    })
        except Exception as e:
            st.warning(f"Nie udaÅ‚o siÄ™ wyekstraktowaÄ‡ obrazÃ³w ze strony {page_index + 1}: {e}")
        
        return images
    
    def _extract_images_from_docx(self) -> List[Dict]:
        """WyciÄ…ga obrazy z dokumentu DOCX"""
        images = []
        try:
            for rel in self._document.part.rels.values():
                if "image" in rel.target_ref:
                    img_data = rel.target_part.blob
                    ext = rel.target_ref.split('.')[-1]
                    images.append({
                        'image': img_data,
                        'ext': ext,
                        'index': len(images)
                    })
        except Exception as e:
            st.warning(f"Nie udaÅ‚o siÄ™ wyekstraktowaÄ‡ obrazÃ³w z DOCX: {e}")
        
        return images
    
    def render_page_as_image(self, page_index: int) -> Optional[bytes]:
        """Renderuje stronÄ™ jako obraz (tylko dla PDF)"""
        if self.file_type != 'pdf':
            return None
        
        try:
            page = self._document.load_page(page_index)
            pix = page.get_pixmap(matrix=fitz.Matrix(2.0, 2.0))
            return pix.tobytes("png")
        except Exception as e:
            st.error(f"BÅ‚Ä…d podczas renderowania strony {page_index + 1}: {e}")
            return None

# ===== LOGIKA AI =====

class AIProcessor:
    """Klasa obsÅ‚ugujÄ…ca komunikacjÄ™ z OpenAI API"""
    
    def __init__(self, api_key: str, model: str = DEFAULT_MODEL):
        self.client = AsyncOpenAI(api_key=api_key)
        self.model = model
    
    def get_system_prompt(self) -> str:
        """Zwraca system prompt dla przetwarzania artykuÅ‚Ã³w"""
        return """JesteÅ› precyzyjnym asystentem redakcyjnym. Twoim celem jest przeksztaÅ‚cenie surowego tekstu w czytelny, dobrze zorganizowany artykuÅ‚ internetowy.

ZASADA NADRZÄ˜DNA: WIERNOÅšÄ† TREÅšCI, ELASTYCZNOÅšÄ† FORMY.
- Nie zmieniaj oryginalnych sformuÅ‚owaÅ„ ani nie parafrazuj tekstu (chyba Å¼e to konieczne dla czytelnoÅ›ci). PrzenieÅ› treÅ›Ä‡ 1:1.
- Twoja rola polega na dodawaniu elementÃ³w strukturalnych i czyszczeniu Å›mieci.

INSTRUKCJE SPECJALNE (KRYTYCZNE):
1. **LISTY:** JeÅ›li widzisz wyliczenia (punkty, myÅ›lniki), formatuj je jako standardowÄ… listÄ™ Markdown:
   - Element listy 1
   - Element listy 2
2. **PRZYPISY/INDEKSY:** JeÅ›li wykryjesz indeksy przypisÃ³w (maÅ‚e cyfry na koÅ„cu zdaÅ„ lub sÅ‚Ã³w), formatuj je uÅ¼ywajÄ…c tagu HTML: `<sup>1</sup>`, `<sup>2</sup>`.
3. **USUWANIE PODPISÃ“W I ÅšMIECI:** BEZWZGLÄ˜DNIE USUWAJ:
   - Podpisy pod zdjÄ™ciami (np. "Rys. 1. Widok...", "Fot. Jan Kowalski").
   - Å¹rÃ³dÅ‚a grafik i tabel (np. "Å¹rÃ³dÅ‚o: opracowanie wÅ‚asne").
   - Numery stron, nagÅ‚Ã³wki i stopki redakcyjne.
   - Etykiety typu "NEWS FLASH".

DOZWOLONE MODYFIKACJE STRUKTURALNE:
1. TytuÅ‚ GÅ‚Ã³wny: `# TytuÅ‚`
2. ÅšrÃ³dtytuÅ‚y: `## ÅšrÃ³dtytuÅ‚` (uÅ¼ywaj ich do rozbijania 'Å›ciany tekstu').
3. Pogrubienia: `**tekst**` (dla kluczowych terminÃ³w i nazw wÅ‚asnych).
4. PodziaÅ‚ na sekcje: `---` (jeÅ›li na stronie sÄ… dwa niepowiÄ…zane tematy).

WYMAGANIA KRYTYCZNE:
- Twoja odpowiedÅº musi byÄ‡ WYÅÄ„CZNIE i BEZWZGLÄ˜DNIE poprawnym obiektem JSON.
- NIE uÅ¼ywaj markdown code blocks (```json). ZwrÃ³Ä‡ TYLKO czysty JSON.

FORMAT ODPOWIEDZI:
{"type": "ARTYKUÅ" lub "REKLAMA", "formatted_text": "Sformatowany tekst w markdown."}"""
    
    def get_meta_tags_prompt(self) -> str:
        """Zwraca prompt dla generowania meta tagÃ³w"""
        return """JesteÅ› ekspertem SEO. Na podstawie poniÅ¼szego tekstu artykuÅ‚u, wygeneruj chwytliwy meta title i zwiÄ™zÅ‚y meta description.

WYMAGANIA:
- Meta title: max 60 znakÃ³w.
- Meta description: max 160 znakÃ³w.
- OdpowiedÅº zwrÃ³Ä‡ jako czysty obiekt JSON bez markdown code blocks.

FORMAT ODPOWIEDZI:
{"meta_title": "TytuÅ‚ meta", "meta_description": "Opis meta."}"""

    def get_seo_prompt(self) -> str:
        """Zwraca prompt dla optymalizacji artykuÅ‚u pod kÄ…tem SEO."""
        return """JesteÅ› Å›wiatowej klasy strategiem SEO i copywriterem. Twoim zadaniem jest przepisanie dostarczonego artykuÅ‚u, aby byÅ‚ maksymalnie zoptymalizowany pod kÄ…tem wyszukiwarek i angaÅ¼ujÄ…cy dla czytelnikÃ³w online.

ZASADY KRYTYCZNE:
1.  **WIERNOÅšÄ† FAKTÃ“W**: Musisz bazowaÄ‡ WYÅÄ„CZNIE na informacjach zawartych w oryginalnym tekÅ›cie. Nie dodawaj Å¼adnych nowych faktÃ³w, danych ani opinii. Twoja rola to restrukturyzacja i optymalizacja.
2.  **ODWRÃ“CONA PIRAMIDA**: Zastosuj zasadÄ™ odwrÃ³conej piramidy. NajwaÅ¼niejsze informacje, kluczowe wnioski i odpowiedzi na potencjalne pytania czytelnika umieÅ›Ä‡ na samym poczÄ…tku artykuÅ‚u.
3.  **STRUKTURA I CZYTELNOÅšÄ†**:
    *   StwÃ³rz nowy, chwytliwy tytuÅ‚ zoptymalizowany pod kÄ…tem potencjalnych fraz kluczowych (H1).
    *   Podziel tekst na logiczne sekcje za pomocÄ… Å›rÃ³dtytuÅ‚Ã³w (H2, H3).
    *   UÅ¼ywaj list punktowanych, jeÅ›li to moÅ¼liwe, aby zwiÄ™kszyÄ‡ czytelnoÅ›Ä‡.
    *   Stosuj pogrubienia (`**tekst**`) dla najwaÅ¼niejszych terminÃ³w.
4.  **JÄ˜ZYK**: UÅ¼ywaj aktywnego, dynamicznego jÄ™zyka. Unikaj strony biernej. Pisz bezpoÅ›rednio do czytelnika.

WYMAGANIA FORMATOWANIA:
- Twoja odpowiedÅº musi byÄ‡ WYÅÄ„CZNIE poprawnym obiektem JSON.
- NIE uÅ¼ywaj blokÃ³w kodu markdown (```json).

FORMAT ODPOWIEDZI JSON:
{"seo_title": "Nowy, zoptymalizowany pod SEO tytuÅ‚ artykuÅ‚u", "seo_article_markdown": "PeÅ‚na treÅ›Ä‡ przepisanego artykuÅ‚u w formacie Markdown, z nagÅ‚Ã³wkami, listami i pogrubieniami."}"""

    async def process_text(self, text: str, system_prompt: str, max_tokens: int = 4096) -> Dict:
        """Przetwarza tekst przez OpenAI API"""
        last_error = None
        content = ""
        
        for attempt in range(MAX_RETRIES):
            try:
                response = await self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": text}
                    ],
                    max_tokens=max_tokens,
                    temperature=0.3,
                    response_format={"type": "json_object"}
                )
                
                content = response.choices[0].message.content
                
                if not content:
                    raise ValueError("API zwrÃ³ciÅ‚o pustÄ… odpowiedÅº.")
                
                return json.loads(content)
                
            except json.JSONDecodeError as e:
                last_error = e
                st.warning(f"PrÃ³ba {attempt + 1}: BÅ‚Ä…d dekodowania JSON. Ponawiam prÃ³bÄ™...")
                await asyncio.sleep(1)
                continue
            except Exception as e:
                last_error = e
                st.warning(f"PrÃ³ba {attempt + 1}: WystÄ…piÅ‚ bÅ‚Ä…d API: {e}. Ponawiam prÃ³bÄ™...")
                await asyncio.sleep(1)
                continue
        
        return {
            "error": f"BÅ‚Ä…d po {MAX_RETRIES} prÃ³bach.",
            "last_known_error": str(last_error),
            "raw_response": content
        }
    
    async def process_page(self, page_content: PageContent) -> Dict:
        """Przetwarza pojedynczÄ… stronÄ™"""
        page_data = {"page_number": page_content.page_number}
        
        if len(page_content.text.split()) < 20:
            page_data["type"] = "pominiÄ™ta"
            page_data["formatted_content"] = "<i>Strona zawiera zbyt maÅ‚o tekstu.</i>"
            return page_data
        
        result = await self.process_text(page_content.text, self.get_system_prompt(), max_tokens=4096)
        
        if "error" in result:
            page_data["type"] = "bÅ‚Ä…d"
            page_data["formatted_content"] = f"""<div class="error-box">
                <strong>{result['error']}</strong><br>
                <i>Ostatni bÅ‚Ä…d: {result['last_known_error']}</i><br>
                <details><summary>PokaÅ¼ surowÄ… odpowiedÅº</summary><pre>{result['raw_response']}</pre></details>
            </div>"""
        else:
            page_data["type"] = result.get("type", "nieznany").lower()
            formatted_text = result.get("formatted_text", "")
            
            if page_data["type"] == "artykuÅ‚":
                page_data["formatted_content"] = markdown_to_html(formatted_text)
                page_data["raw_markdown"] = formatted_text
            else:
                page_data["formatted_content"] = f"<i>Zidentyfikowano jako: <strong>{page_data['type'].upper()}</strong>.</i>"
        
        return page_data
    
    async def process_article_group(self, pages_content: List[PageContent]) -> Dict:
        """Przetwarza grupÄ™ stron jako jeden artykuÅ‚"""
        page_numbers = [p.page_number for p in pages_content]
        
        combined_text = "\n\n".join([
            f"--- STRONA {p.page_number} ---\n{p.text.strip()}"
            for p in pages_content
        ])
        
        result = await self.process_text(combined_text, self.get_system_prompt(), max_tokens=8192)
        
        article_data = {"page_numbers": page_numbers}
        
        if "error" in result:
            article_data["type"] = "bÅ‚Ä…d"
            article_data["formatted_content"] = f"""<div class='error-box'>
                <strong>{result['error']}</strong><br>
                <i>Ostatni bÅ‚Ä…d: {result['last_known_error']}</i><br>
                <details><summary>PokaÅ¼ surowÄ… odpowiedÅº</summary><pre>{result['raw_response']}</pre></details>
            </div>"""
        else:
            article_data["type"] = result.get("type", "nieznany").lower()
            formatted_text = result.get("formatted_text", "")
            
            if article_data["type"] == "artykuÅ‚":
                article_data["formatted_content"] = markdown_to_html(formatted_text)
                article_data["raw_markdown"] = formatted_text
            else:
                article_data["formatted_content"] = f"<i>Zidentyfikowano jako: <strong>{article_data['type'].upper()}</strong>.</i>"
        
        return article_data
    
    async def generate_meta_tags(self, article_text: str) -> Dict:
        """Generuje meta tagi dla artykuÅ‚u"""
        prompt = self.get_meta_tags_prompt()
        return await self.process_text(article_text[:4000], prompt, max_tokens=200)

    async def generate_seo_article(self, article_text: str) -> Dict:
        """Przepisuje artykuÅ‚ pod kÄ…tem SEO"""
        prompt = self.get_seo_prompt()
        return await self.process_text(article_text, prompt, max_tokens=4096)

# ===== FUNKCJE POMOCNICZE =====

def markdown_to_html(text: str) -> str:
    """Konwertuje markdown na HTML z obsÅ‚ugÄ… list i indeksÃ³w"""
    # 1. ObsÅ‚uga struktury nagÅ‚Ã³wkÃ³w i linii
    text = text.replace('\n---\n', '\n<hr>\n')
    text = re.sub(r'^\s*# (.*?)\s*$', r'<h2>\1</h2>', text, flags=re.MULTILINE)
    text = re.sub(r'^\s*## (.*?)\s*$', r'<h3>\1</h3>', text, flags=re.MULTILINE)
    text = re.sub(r'^\s*### (.*?)\s*$', r'<h4>\1</h4>', text, flags=re.MULTILINE)
    text = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', text)
    
    # 2. ObsÅ‚uga list (zamiana linii z myÅ›lnikami na <ul><li>...</li></ul>)
    lines = text.split('\n')
    new_lines = []
    in_list = False
    
    for line in lines:
        stripped = line.strip()
        # Wykrywanie elementu listy (myÅ›lnik lub gwiazdka na poczÄ…tku)
        if stripped.startswith(('- ', '* ')):
            if not in_list:
                new_lines.append("<ul>")
                in_list = True
            content = stripped[2:] # UsuniÄ™cie "- "
            new_lines.append(f"<li>{content}</li>")
        else:
            if in_list:
                new_lines.append("</ul>")
                in_list = False
            new_lines.append(line)
            
    if in_list:
        new_lines.append("</ul>")
        
    text = '\n'.join(new_lines)
    
    # 3. PodziaÅ‚ na akapity (z pominiÄ™ciem blokÃ³w, ktÃ³re juÅ¼ sÄ… HTMLem)
    paragraphs = text.split('\n\n')
    html_content = []
    
    for para in paragraphs:
        stripped_para = para.strip()
        if not stripped_para:
            continue
            
        # SprawdÅº czy to element blokowy HTML (nagÅ‚Ã³wek, lista, hr)
        if stripped_para.startswith(('<h', '<hr', '<ul', '<li')):
            html_content.append(stripped_para)
        else:
            # Zachowaj tagi <sup> jeÅ›li sÄ… w tekÅ›cie, zamieÅ„ nowÄ… liniÄ™ na <br>
            formatted_para = stripped_para.replace(chr(10), '<br>')
            html_content.append(f"<p>{formatted_para}</p>")
    
    return ''.join(html_content)

def markdown_to_clean_html(markdown_text: str, page_number: int = None) -> str:
    """
    Konwertuje markdown na czysty HTML bez stylowania
    Tylko struktura: h1-h4, p, strong, hr, ul, li, sup
    """
    html = markdown_text
    
    html = html.replace('\n---\n', '\n<hr>\n')
    html = html.replace('\n--- \n', '\n<hr>\n')
    
    html = re.sub(r'^\s*# (.*?)\s*$', r'<h1>\1</h1>', html, flags=re.MULTILINE)
    html = re.sub(r'^\s*## (.*?)\s*$', r'<h2>\1</h2>', html, flags=re.MULTILINE)
    html = re.sub(r'^\s*### (.*?)\s*$', r'<h3>\1</h3>', html, flags=re.MULTILINE)
    html = re.sub(r'^\s*#### (.*?)\s*$', r'<h4>\1</h4>', html, flags=re.MULTILINE)
    html = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', html)

    # ObsÅ‚uga list w czystym HTML
    lines = html.split('\n')
    new_lines = []
    in_list = False
    
    for line in lines:
        stripped = line.strip()
        if stripped.startswith(('- ', '* ')):
            if not in_list:
                new_lines.append("<ul>")
                in_list = True
            content = stripped[2:]
            new_lines.append(f"<li>{content}</li>")
        else:
            if in_list:
                new_lines.append("</ul>")
                in_list = False
            new_lines.append(line)
    
    if in_list:
        new_lines.append("</ul>")
        
    html = '\n'.join(new_lines)
    
    # PodziaÅ‚ na akapity
    paragraphs = html.split('\n\n')
    formatted_paragraphs = []
    
    for para in paragraphs:
        para = para.strip()
        if not para:
            continue
        
        # JeÅ›li linia zaczyna siÄ™ od tagu HTML, nie pakuj jej w <p>
        if para.startswith(('<h1', '<h2', '<h3', '<h4', '<hr', '<p', '<ul')):
            formatted_paragraphs.append(para)
        else:
            para_with_breaks = para.replace('\n', '<br>\n')
            formatted_paragraphs.append(f'<p>{para_with_breaks}</p>')
    
    return '\n'.join(formatted_paragraphs)

def generate_full_html_document(content: str, title: str = "ArtykuÅ‚", meta_title: str = None, meta_description: str = None) -> str:
    """
    Generuje peÅ‚ny dokument HTML z czystÄ… strukturÄ… (bez CSS)
    """
    meta_tags = ""
    if meta_title:
        meta_tags += f'    <meta name="title" content="{meta_title}">\n'
    if meta_description:
        meta_tags += f'    <meta name="description" content="{meta_description}">\n'
    
    html_doc = f"""<!DOCTYPE html>
<html lang="pl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{title}</title>
{meta_tags}</head>
<body>
{content}
</body>
</html>"""
    
    return html_doc

def get_article_html_from_page(page_index: int) -> Optional[Dict]:
    """
    Pobiera czysty HTML artykuÅ‚u dla danej strony
    """
    page_result = st.session_state.extracted_pages[page_index]
    
    if not page_result or page_result.get('type') != 'artykuÅ‚':
        return None
    
    if 'raw_markdown' not in page_result:
        return None
    
    group_pages = page_result.get('group_pages', [])
    
    if group_pages and len(group_pages) > 1:
        first_page_index = group_pages[0] - 1
        first_page_result = st.session_state.extracted_pages[first_page_index]
        
        markdown_content = first_page_result.get('raw_markdown', '')
        title = f"ArtykuÅ‚ ze stron {group_pages[0]}-{group_pages[-1]}"
        pages = group_pages
    else:
        markdown_content = page_result.get('raw_markdown', '')
        title = f"ArtykuÅ‚ ze strony {page_index + 1}"
        pages = [page_index + 1]
    
    html_content = markdown_to_clean_html(markdown_content)
    
    meta_title = None
    meta_description = None
    
    if page_index in st.session_state.meta_tags:
        tags = st.session_state.meta_tags[page_index]
        if 'error' not in tags:
            meta_title = tags.get('meta_title')
            meta_description = tags.get('meta_description')
    
    html_document = generate_full_html_document(
        html_content,
        title=title,
        meta_title=meta_title,
        meta_description=meta_description
    )
    
    return {
        'html_content': html_content,
        'html_document': html_document,
        'title': title,
        'pages': pages,
        'meta_title': meta_title,
        'meta_description': meta_description
    }

def sanitize_filename(name: str) -> str:
    """Sanityzuje nazwÄ™ pliku"""
    if not name:
        return "unnamed_project"
    sanitized = re.sub(r'[\\/*?:"<>|]', "_", str(name))
    return re.sub(r'_{2,}', "_", sanitized).strip("_") or "unnamed_project"

def create_zip_archive(data: List[Dict]) -> bytes:
    """Tworzy archiwum ZIP"""
    zip_buffer = io.BytesIO()
    with zipfile.ZipFile(zip_buffer, "w", zipfile.ZIP_DEFLATED) as zf:
        for item in data:
            zf.writestr(item['name'], item['content'])
    return zip_buffer.getvalue()

def parse_page_groups(input_text: str, total_pages: int) -> List[List[int]]:
    """Parsuje zakresy stron z tekstu wejÅ›ciowego"""
    if not input_text:
        raise ValueError("Nie podano zakresÃ³w stron.")
    
    groups = []
    used_pages = set()
    
    for line in re.split(r'[;\n]+', input_text):
        line = line.strip()
        if not line:
            continue
        
        pages = []
        for part in re.split(r'[;,]+', line):
            part = part.strip()
            if not part:
                continue
            
            if '-' in part:
                start_str, end_str = part.split('-', 1)
                if not start_str.isdigit() or not end_str.isdigit():
                    raise ValueError(f"Niepoprawny zakres stron: '{part}'.")
                
                start, end = int(start_str), int(end_str)
                if start > end:
                    raise ValueError(f"Zakres stron musi byÄ‡ rosnÄ…cy: '{part}'.")
                if start < 1 or end > total_pages:
                    raise ValueError(f"Zakres '{part}' wykracza poza liczbÄ™ stron dokumentu.")
                
                pages.extend(range(start, end + 1))
            else:
                if not part.isdigit():
                    raise ValueError(f"Niepoprawny numer strony: '{part}'.")
                
                page = int(part)
                if page < 1 or page > total_pages:
                    raise ValueError(f"Strona '{page}' wykracza poza dokument.")
                
                pages.append(page)
        
        if not pages:
            continue
        
        pages = sorted(dict.fromkeys(pages))
        
        if any(p in used_pages for p in pages):
            raise ValueError(f"Strony {pages} zostaÅ‚y juÅ¼ przypisane do innego artykuÅ‚u.")
        
        used_pages.update(pages)
        groups.append(pages)
    
    if not groups:
        raise ValueError("Nie znaleziono Å¼adnych poprawnych zakresÃ³w stron.")
    
    return groups

# ===== ZARZÄ„DZANIE PROJEKTAMI =====

def ensure_projects_dir() -> bool:
    """Tworzy katalog projektÃ³w jeÅ›li nie istnieje"""
    try:
        PROJECTS_DIR.mkdir(exist_ok=True)
        return True
    except Exception as e:
        st.error(f"Nie moÅ¼na utworzyÄ‡ katalogu projektÃ³w: {e}")
        return False

def get_existing_projects() -> List[str]:
    """Zwraca listÄ™ istniejÄ…cych projektÃ³w"""
    if not ensure_projects_dir():
        return []
    return [d.name for d in PROJECTS_DIR.iterdir() if d.is_dir()]

def save_project():
    """Zapisuje projekt do pliku"""
    if not st.session_state.project_name or not ensure_projects_dir():
        st.error("Nie moÅ¼na zapisaÄ‡ projektu: brak nazwy projektu.")
        return
    
    project_path = PROJECTS_DIR / st.session_state.project_name
    project_path.mkdir(exist_ok=True)
    
    state_to_save = {
        k: v for k, v in st.session_state.items()
        if k not in ['document', 'project_loaded_and_waiting_for_file']
    }
    state_to_save['extracted_pages'] = [
        p for p in st.session_state.extracted_pages if p is not None
    ]
    
    try:
        with open(project_path / "project_state.json", "w", encoding="utf-8") as f:
            json.dump(state_to_save, f, indent=2, ensure_ascii=False)
        st.toast(f"âœ… Projekt '{st.session_state.project_name}' zostaÅ‚ zapisany!", icon="ğŸ’¾")
    except Exception as e:
        st.error(f"BÅ‚Ä…d podczas zapisywania projektu: {e}")

def load_project(project_name: str):
    """Åaduje projekt z pliku"""
    project_file = PROJECTS_DIR / project_name / "project_state.json"
    
    if not project_file.exists():
        st.error(f"Plik projektu '{project_name}' nie istnieje.")
        return
    
    try:
        with open(project_file, "r", encoding="utf-8") as f:
            state_to_load = json.load(f)
        
        for key, value in state_to_load.items():
            if key != 'document':
                st.session_state[key] = value
        
        total_pages = st.session_state.get('total_pages', 0)
        st.session_state.extracted_pages = [None] * total_pages
        
        for page_data in state_to_load.get('extracted_pages', []):
            page_num_one_based = page_data.get('page_number')
            if page_num_one_based and 1 <= page_num_one_based <= total_pages:
                st.session_state.extracted_pages[page_num_one_based - 1] = page_data
        
        st.session_state.document = None
        st.session_state.project_loaded_and_waiting_for_file = True
        
        st.success(f"âœ… ZaÅ‚adowano projekt '{project_name}'. Wgraj powiÄ…zany plik, aby kontynuowaÄ‡.")
    except Exception as e:
        st.error(f"BÅ‚Ä…d podczas Å‚adowania projektu: {e}")

# ===== OBSÅUGA PLIKÃ“W =====

def handle_file_upload(uploaded_file):
    """ObsÅ‚uguje wgranie pliku"""
    try:
        with st.spinner("Åadowanie pliku..."):
            file_bytes = uploaded_file.read()
            document = DocumentHandler(file_bytes, uploaded_file.name)
            
            if st.session_state.project_loaded_and_waiting_for_file:
                if document.get_page_count() != st.session_state.total_pages:
                    st.error(
                        f"BÅ‚Ä…d: Wgrany plik ma {document.get_page_count()} stron, "
                        f"a projekt oczekuje {st.session_state.total_pages}. Wgraj wÅ‚aÅ›ciwy plik."
                    )
                    return
                
                st.session_state.document = document
                st.session_state.uploaded_filename = uploaded_file.name
                st.session_state.file_type = document.file_type
                st.session_state.project_loaded_and_waiting_for_file = False
                st.success("âœ… Plik pomyÅ›lnie dopasowany do projektu.")
            else:
                for key, value in SESSION_STATE_DEFAULTS.items():
                    if key != 'api_key':
                        st.session_state[key] = value
                
                st.session_state.document = document
                st.session_state.uploaded_filename = uploaded_file.name
                st.session_state.file_type = document.file_type
                st.session_state.project_name = sanitize_filename(Path(uploaded_file.name).stem)
                st.session_state.total_pages = document.get_page_count()
                st.session_state.extracted_pages = [None] * document.get_page_count()
                st.session_state.end_page = document.get_page_count()
                
                st.success(f"âœ… ZaÅ‚adowano plik: {uploaded_file.name} ({document.file_type.upper()})")
    
    except Exception as e:
        st.error(f"âŒ BÅ‚Ä…d Å‚adowania pliku: {e}")
        st.session_state.document = None
    
    st.rerun()

# ===== PRZETWARZANIE AI =====

async def process_batch(ai_processor: AIProcessor, start_index: int):
    """Przetwarza batch stron"""
    processing_limit = st.session_state.processing_end_page_index + 1
    end_index = min(start_index + BATCH_SIZE, processing_limit)
    
    tasks = []
    for i in range(start_index, end_index):
        if st.session_state.document:
            page_content = st.session_state.document.get_page_content(i)
            tasks.append(ai_processor.process_page(page_content))
    
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    for i, result in enumerate(results):
        page_index = start_index + i
        if isinstance(result, Exception):
            st.session_state.extracted_pages[page_index] = {
                "page_number": page_index + 1,
                "type": "bÅ‚Ä…d",
                "formatted_content": f"BÅ‚Ä…d: {result}"
            }
        else:
            st.session_state.extracted_pages[page_index] = result

def start_ai_processing():
    """Rozpoczyna przetwarzanie AI"""
    if st.session_state.processing_mode == 'article':
        try:
            groups = parse_page_groups(
                st.session_state.article_page_groups_input,
                st.session_state.total_pages
            )
            
            for group in groups:
                for page in group:
                    st.session_state.extracted_pages[page - 1] = None
            
            st.session_state.article_groups = groups
            st.session_state.next_article_index = 0
            st.session_state.processing_status = 'in_progress'
            
            # Automatycznie przejdÅº do pierwszej strony pierwszego artykuÅ‚u
            if groups:
                st.session_state.current_page = groups[0][0] - 1
            
        except ValueError as e:
            st.error(str(e))
            return
    else:
        if st.session_state.processing_mode == 'all':
            start_idx = 0
            end_idx = st.session_state.total_pages - 1
        else:
            start_idx = st.session_state.start_page - 1
            end_idx = st.session_state.end_page - 1
        
        if start_idx > end_idx:
            st.error("Strona poczÄ…tkowa nie moÅ¼e byÄ‡ wiÄ™ksza niÅ¼ koÅ„cowa.")
            return
        
        for i in range(start_idx, end_idx + 1):
            st.session_state.extracted_pages[i] = None
        
        st.session_state.processing_status = 'in_progress'
        st.session_state.next_batch_start_index = start_idx
        st.session_state.processing_end_page_index = end_idx
        
        # Automatycznie przejdÅº do pierwszej przetwarzanej strony
        st.session_state.current_page = start_idx

def run_ai_processing_loop():
    """GÅ‚Ã³wna pÄ™tla przetwarzania AI"""
    if not st.session_state.api_key:
        st.error("Klucz API OpenAI nie jest skonfigurowany.")
        st.session_state.processing_status = 'idle'
        return
    
    ai_processor = AIProcessor(st.session_state.api_key, st.session_state.model)
    
    if st.session_state.processing_mode == 'article':
        if st.session_state.next_article_index < len(st.session_state.article_groups):
            article_pages = st.session_state.article_groups[st.session_state.next_article_index]
            
            pages_content = []
            for page_num in article_pages:
                if st.session_state.document and 0 <= page_num - 1 < st.session_state.total_pages:
                    pages_content.append(
                        st.session_state.document.get_page_content(page_num - 1)
                    )
            
            article_result = asyncio.run(
                ai_processor.process_article_group(pages_content)
            )
            
            for page in article_pages:
                page_index = page - 1
                if 0 <= page_index < len(st.session_state.extracted_pages):
                    entry = {
                        key: value for key, value in article_result.items()
                        if key != 'page_numbers'
                    }
                    entry['page_number'] = page
                    entry['group_pages'] = article_pages
                    entry['is_group_lead'] = (page == article_pages[0])
                    st.session_state.extracted_pages[page_index] = entry
            
            st.session_state.next_article_index += 1
        else:
            st.session_state.processing_status = 'complete'
    else:
        if st.session_state.next_batch_start_index <= st.session_state.processing_end_page_index:
            asyncio.run(
                process_batch(ai_processor, st.session_state.next_batch_start_index)
            )
            st.session_state.next_batch_start_index += BATCH_SIZE
        else:
            st.session_state.processing_status = 'complete'
    
    st.rerun()

# ===== UI COMPONENTS =====

def init_session_state():
    """Inicjalizuje stan sesji"""
    if 'api_key' not in st.session_state or st.session_state.api_key is None:
        st.session_state.api_key = st.secrets.get("openai", {}).get("api_key")
    
    for key, value in SESSION_STATE_DEFAULTS.items():
        if key not in st.session_state:
            st.session_state[key] = value

def render_sidebar():
    """Renderuje panel boczny"""
    with st.sidebar:
        st.header("âš™ï¸ Konfiguracja Projektu")
        
        projects = get_existing_projects()
        selected_project = st.selectbox(
            "Wybierz istniejÄ…cy projekt",
            ["Nowy projekt"] + projects
        )
        
        if st.button("ZaÅ‚aduj projekt", disabled=(selected_project == "Nowy projekt")):
            load_project(selected_project)
            st.rerun()
        
        st.divider()
        
        supported_formats = ["pdf"]
        if DOCX_AVAILABLE:
            supported_formats.append("docx")
        if MAMMOTH_AVAILABLE:
            supported_formats.append("doc")
        
        file_label = f"Wybierz plik ({', '.join(f.upper() for f in supported_formats)})"
        
        uploaded_file = st.file_uploader(
            file_label,
            type=supported_formats
        )
        
        if uploaded_file:
            if (st.session_state.project_loaded_and_waiting_for_file or
                uploaded_file.name != st.session_state.get('uploaded_filename')):
                handle_file_upload(uploaded_file)
        
        if st.session_state.document:
            st.divider()
            st.subheader("ğŸ¤– Opcje Przetwarzania")
            
            st.radio(
                "Wybierz tryb:",
                ('all', 'range', 'article'),
                captions=[
                    "CaÅ‚y dokument (strona po stronie)",
                    "Zakres stron (strona po stronie)",
                    "ArtykuÅ‚ wielostronicowy (jedno zapytanie)"
                ],
                key='processing_mode',
                horizontal=False
            )
            
            if st.session_state.processing_mode == 'range':
                c1, c2 = st.columns(2)
                c1.number_input(
                    "Od strony",
                    min_value=1,
                    max_value=st.session_state.total_pages,
                    key='start_page'
                )
                c2.number_input(
                    "Do strony",
                    min_value=st.session_state.start_page,
                    max_value=st.session_state.total_pages,
                    key='end_page'
                )
            
            elif st.session_state.processing_mode == 'article':
                st.info("Podaj grupy stron dla artykuÅ‚Ã³w wielostronicowych. KaÅ¼da grupa zostanie przetworzona w jednym zapytaniu do AI.")
                st.text_area(
                    "Zakresy stron artykuÅ‚Ã³w (np. 1-3; 5,6)",
                    key='article_page_groups_input',
                    placeholder="1-3\n5,6\n8-10",
                    height=100
                )
            
            st.divider()
            
            processing_disabled = (
                st.session_state.processing_status == 'in_progress' or
                not st.session_state.api_key
            )
            
            button_text = (
                "ğŸ”„ Przetwarzanie..."
                if st.session_state.processing_status == 'in_progress'
                else "ğŸš€ Rozpocznij Przetwarzanie"
            )
            
            if st.button(
                button_text,
                use_container_width=True,
                type="primary",
                disabled=processing_disabled
            ):
                start_ai_processing()
                st.rerun()
            
            st.divider()
            
            st.info(f"**Projekt:** {st.session_state.project_name}")
            st.metric("Liczba stron", st.session_state.total_pages)
            st.caption(f"**Format:** {st.session_state.file_type.upper()}")

def render_processing_status():
    """Renderuje status przetwarzania"""
    if st.session_state.processing_status == 'idle' or not st.session_state.document:
        return
    
    processed_count = sum(1 for p in st.session_state.extracted_pages if p is not None)
    
    if st.session_state.processing_mode == 'article':
        total_groups = len(st.session_state.article_groups)
        processed_groups = st.session_state.next_article_index
        progress = processed_groups / total_groups if total_groups > 0 else 0
        
        if st.session_state.processing_status == 'complete':
            st.success(f"âœ… Przetwarzanie zakoÅ„czone! Przetworzono {total_groups} artykuÅ‚(Ã³w).")
            
            # Przycisk szybkiej nawigacji do pierwszego artykuÅ‚u
            if st.session_state.article_groups:
                if st.button("ğŸ“– PrzejdÅº do pierwszego artykuÅ‚u", type="secondary"):
                    st.session_state.current_page = st.session_state.article_groups[0][0] - 1
                    st.rerun()
        else:
            st.info(f"ğŸ”„ Przetwarzanie artykuÅ‚Ã³w... ({processed_groups}/{total_groups})")
            st.progress(progress)
    else:
        progress = processed_count / st.session_state.total_pages if st.session_state.total_pages > 0 else 0
        
        if st.session_state.processing_status == 'complete':
            st.success("âœ… Przetwarzanie zakoÅ„czone!")
            
            # Przyciski szybkiej nawigacji do zakresu
            if st.session_state.processing_mode == 'range':
                nav_button_cols = st.columns(2)
                if nav_button_cols[0].button("ğŸ“– PrzejdÅº do poczÄ…tku zakresu", type="secondary"):
                    st.session_state.current_page = st.session_state.start_page - 1
                    st.rerun()
                if nav_button_cols[1].button("ğŸ“– PrzejdÅº do koÅ„ca zakresu", type="secondary"):
                    st.session_state.current_page = st.session_state.end_page - 1
                    st.rerun()
        else:
            st.info(f"ğŸ”„ Przetwarzanie w toku... (UkoÅ„czono {processed_count}/{st.session_state.total_pages} stron)")
            st.progress(progress)
    
    c1, c2, _ = st.columns([1, 1, 3])
    
    if c1.button("ğŸ’¾ Zapisz postÄ™p", use_container_width=True):
        save_project()
    
    articles = [
        p for p in st.session_state.extracted_pages
        if p and p.get('type') == 'artykuÅ‚' and p.get('is_group_lead', True)
    ]
    
    if articles:
        zip_data = [
            {
                'name': f"artykul_ze_str_{a['page_number']}.txt",
                'content': a['raw_markdown'].encode('utf-8')
            }
            for a in articles if 'raw_markdown' in a
        ]
        
        if zip_data:
            c2.download_button(
                "ğŸ“¥ Pobierz artykuÅ‚y",
                create_zip_archive(zip_data),
                f"{st.session_state.project_name}_artykuly.zip",
                "application/zip",
                use_container_width=True
            )

def render_navigation():
    """Renderuje nawigacjÄ™ miÄ™dzy stronami"""
    if st.session_state.total_pages <= 1:
        return
    
    st.subheader("ğŸ“– Nawigacja")
    
    # Informacja o zakresie przetwarzania
    if st.session_state.processing_mode == 'range':
        processing_range = f"{st.session_state.start_page}-{st.session_state.end_page}"
        st.info(f"ğŸ¯ Przetwarzany zakres: strony {processing_range}")
        
        # Przyciski szybkiej nawigacji
        nav_cols = st.columns(3)
        if nav_cols[0].button("â®ï¸ PoczÄ…tek zakresu", use_container_width=True):
            st.session_state.current_page = st.session_state.start_page - 1
            st.rerun()
        if nav_cols[1].button("â­ï¸ Koniec zakresu", use_container_width=True):
            st.session_state.current_page = st.session_state.end_page - 1
            st.rerun()
        if nav_cols[2].button("ğŸ  PoczÄ…tek dokumentu", use_container_width=True):
            st.session_state.current_page = 0
            st.rerun()
        
        st.divider()
    
    elif st.session_state.processing_mode == 'article' and st.session_state.article_groups:
        st.info(f"ğŸ¯ Liczba artykuÅ‚Ã³w: {len(st.session_state.article_groups)}")
        
        # Przyciski nawigacji do artykuÅ‚Ã³w
        article_nav_cols = st.columns(min(len(st.session_state.article_groups), 5))
        for idx, group in enumerate(st.session_state.article_groups[:5]):
            label = f"Art. {idx+1}"
            if len(group) > 1:
                label += f" ({group[0]}-{group[-1]})"
            else:
                label += f" (str. {group[0]})"
            
            if article_nav_cols[idx % 5].button(label, use_container_width=True, key=f"nav_art_{idx}"):
                st.session_state.current_page = group[0] - 1
                st.rerun()
        
        if len(st.session_state.article_groups) > 5:
            st.caption(f"... i jeszcze {len(st.session_state.article_groups) - 5} artykuÅ‚Ã³w")
        
        st.divider()
    
    # Standardowa nawigacja
    c1, c2, c3 = st.columns([1, 2, 1])
    
    if c1.button(
        "â¬…ï¸ Poprzednia",
        use_container_width=True,
        disabled=(st.session_state.current_page == 0)
    ):
        st.session_state.current_page -= 1
        st.rerun()
    
    c2.metric("Strona", f"{st.session_state.current_page + 1} / {st.session_state.total_pages}")
    
    if c3.button(
        "NastÄ™pna â¡ï¸",
        use_container_width=True,
        disabled=(st.session_state.current_page >= st.session_state.total_pages - 1)
    ):
        st.session_state.current_page += 1
        st.rerun()
    
    # Slider nawigacji
    new_page = st.slider(
        "PrzejdÅº do strony:",
        1,
        st.session_state.total_pages,
        st.session_state.current_page + 1
    ) - 1
    
    if new_page != st.session_state.current_page:
        st.session_state.current_page = new_page
        st.rerun()

def render_page_view():
    """Renderuje widok strony"""
    st.divider()
    
    page_index = st.session_state.current_page
    page_content = st.session_state.document.get_page_content(page_index)
    
    pdf_col, text_col = st.columns(2, gap="large")
    
    with pdf_col:
        st.subheader(f"ğŸ“„ OryginaÅ‚ (Strona {page_index + 1})")
        
        if st.session_state.file_type == 'pdf':
            image_data = st.session_state.document.render_page_as_image(page_index)
            if image_data:
                st.image(image_data, use_container_width=True)
            else:
                st.error("Nie moÅ¼na wyÅ›wietliÄ‡ podglÄ…du strony.")
        else:
            st.info(f"PodglÄ…d nie jest dostÄ™pny dla plikÃ³w {st.session_state.file_type.upper()}.")
        
        if page_content.images:
            with st.expander(f"ğŸ–¼ï¸ PokaÅ¼/ukryj {len(page_content.images)} obraz(y)"):
                for img in page_content.images:
                    st.image(
                        img['image'],
                        caption=f"Obraz {img['index'] + 1}",
                        use_container_width=True
                    )
            
            img_zip = create_zip_archive([
                {
                    'name': f"str_{page_index+1}_img_{i['index']}.{i['ext']}",
                    'content': i['image']
                }
                for i in page_content.images
            ])
            
            st.download_button(
                "Pobierz obrazy",
                img_zip,
                f"obrazy_strona_{page_index+1}.zip",
                "application/zip",
                use_container_width=True
            )
    
    with text_col:
        st.subheader("ğŸ¤– Tekst przetworzony przez AI")
        
        with st.expander("ğŸ‘ï¸ PokaÅ¼ surowy tekst wejÅ›ciowy"):
            st.text_area(
                "Surowy tekst",
                page_content.text,
                height=200,
                disabled=True,
                key=f"raw_text_{page_index}"
            )
        
        page_result = st.session_state.extracted_pages[page_index]
        
        if page_result:
            page_type = page_result.get('type', 'nieznany')
            color_map = {
                "artykuÅ‚": "green",
                "reklama": "orange",
                "pominiÄ™ta": "grey",
                "bÅ‚Ä…d": "red"
            }
            color = color_map.get(page_type, "red")
            
            st.markdown(
                f"**Status:** <span style='color:{color}; text-transform:uppercase;'>"
                f"**{page_type}**</span>",
                unsafe_allow_html=True
            )
            
            group_pages = page_result.get('group_pages', [])
            if group_pages and len(group_pages) > 1:
                st.info(f"Ten artykuÅ‚ obejmuje strony: {', '.join(str(p) for p in group_pages)}.")
            
            st.markdown(
                f"<div class='page-text-wrapper'>{page_result.get('formatted_content', '')}</div>",
                unsafe_allow_html=True
            )
            
            # --- PRZYCISKI AKCJI ---
            st.write("---")
            st.markdown("**Akcje Redakcyjne:**")
            
            allow_actions = (
                page_type == 'artykuÅ‚' and
                'raw_markdown' in page_result and
                page_result.get('is_group_lead', True)
            )

            action_cols = st.columns(4)
            
            if action_cols[0].button(
                "ğŸ”„ PrzetwÃ³rz ponownie",
                key=f"reroll_{page_index}",
                use_container_width=True
            ):
                handle_page_reroll(page_index)
            
            if action_cols[1].button(
                "âœ¨ Generuj Meta",
                key=f"meta_{page_index}",
                use_container_width=True,
                disabled=not allow_actions
            ):
                handle_meta_tag_generation(page_index, page_result['raw_markdown'])
            
            if action_cols[2].button(
                "ğŸš€ Optymalizuj dla SEO",
                key=f"seo_{page_index}",
                use_container_width=True,
                disabled=not allow_actions,
                help="Przepisz artykuÅ‚ zgodnie z zasadami SEO"
            ):
                handle_seo_generation(page_index, page_result['raw_markdown'])

            # Checkbox do pokazywania HTML
            show_html = action_cols[3].checkbox(
                "ğŸ“„ PokaÅ¼ HTML",
                key=f"show_html_checkbox_{page_index}",
                disabled=not allow_actions,
                help="PokaÅ¼ i pobierz czysty HTML artykuÅ‚u"
            )
            
            # WYÅšWIETLENIE HTML JEÅšLI CHECKBOX ZAZNACZONY
            if show_html and allow_actions:
                html_data = get_article_html_from_page(page_index)
                
                if html_data:
                    st.divider()
                    
                    with st.expander("ğŸ“„ Czysty HTML artykuÅ‚u", expanded=True):
                        st.caption(f"**{html_data['title']}**")
                        
                        # Taby dla rÃ³Å¼nych widokÃ³w
                        tab1, tab2 = st.tabs(["ğŸ’» Kod HTML (zawartoÅ›Ä‡)", "ğŸ“° PeÅ‚ny dokument HTML"])
                        
                        with tab1:
                            st.code(html_data['html_content'], language='html', line_numbers=True)
                            
                            st.download_button(
                                label="ğŸ“¥ Pobierz zawartoÅ›Ä‡ HTML",
                                data=html_data['html_content'],
                                file_name=f"{sanitize_filename(html_data['title'])}_content.html",
                                mime="text/html",
                                use_container_width=True,
                                key=f"download_content_{page_index}"
                            )
                        
                        with tab2:
                            st.code(html_data['html_document'], language='html', line_numbers=True)
                            
                            st.download_button(
                                label="ğŸ“¥ Pobierz peÅ‚ny dokument HTML",
                                data=html_data['html_document'],
                                file_name=f"{sanitize_filename(html_data['title'])}.html",
                                mime="text/html",
                                use_container_width=True,
                                key=f"download_full_{page_index}"
                            )
                        
                        if html_data['meta_title'] or html_data['meta_description']:
                            st.info("â„¹ï¸ Ten HTML zawiera wygenerowane meta tagi SEO")
            
            # --- WYNIKI AKCJI ---

            # META TAGI
            if page_index in st.session_state.meta_tags:
                tags = st.session_state.meta_tags[page_index]
                
                if "error" in tags:
                    st.error(f"BÅ‚Ä…d generowania meta tagÃ³w: {tags['error']}")
                else:
                    with st.expander("Wygenerowane Meta Tagi âœ¨", expanded=False):
                        st.text_input(
                            "Meta Title",
                            value=tags.get("meta_title", ""),
                            key=f"mt_{page_index}"
                        )
                        st.text_area(
                            "Meta Description",
                            value=tags.get("meta_description", ""),
                            key=f"md_{page_index}"
                        )
            
            if page_index in st.session_state.seo_articles:
                seo_result = st.session_state.seo_articles[page_index]
                with st.expander("ğŸ¤– Zoptymalizowany ArtykuÅ‚ SEO", expanded=True):
                    if "error" in seo_result:
                        st.error(f"BÅ‚Ä…d podczas optymalizacji SEO: {seo_result['error']}")
                        st.json(seo_result)
                    else:
                        seo_title = seo_result.get("seo_title", "Brak tytuÅ‚u")
                        seo_markdown = seo_result.get("seo_article_markdown", "Brak treÅ›ci.")
                        
                        st.markdown(f"### {seo_title}")
                        st.markdown(seo_markdown, unsafe_allow_html=True)
                        st.download_button(
                            label="ğŸ“¥ Pobierz wersjÄ™ SEO (.txt)",
                            data=f"# {seo_title}\n\n{seo_markdown}",
                            file_name=f"{sanitize_filename(seo_title)}.txt",
                            mime="text/plain",
                            use_container_width=True,
                            key=f"download_seo_{page_index}"
                        )

        else:
            if st.session_state.processing_status == 'in_progress':
                st.info("â³ Strona oczekuje na przetworzenie...")
            else:
                st.info("Uruchom przetwarzanie w panelu bocznym.")

def handle_page_reroll(page_index: int):
    """Przetwarza stronÄ™ ponownie z kontekstem"""
    with st.spinner("Przetwarzanie strony z kontekstem..."):
        prev_text = ""
        if page_index > 0:
            prev_content = st.session_state.document.get_page_content(page_index - 1)
            prev_text = prev_content.text
        
        curr_content = st.session_state.document.get_page_content(page_index)
        curr_text = curr_content.text
        
        next_text = ""
        if page_index < st.session_state.total_pages - 1:
            next_content = st.session_state.document.get_page_content(page_index + 1)
            next_text = next_content.text
        
        context_text = (
            f"KONTEKST (POPRZEDNIA STRONA):\n{prev_text}\n\n"
            f"--- STRONA DOCELOWA ---\n{curr_text}\n\n"
            f"KONTEKST (NASTÄ˜PNA STRONA):\n{next_text}"
        )
        
        ai_processor = AIProcessor(st.session_state.api_key, st.session_state.model)
        page_content = PageContent(page_index + 1, context_text)
        new_result = asyncio.run(ai_processor.process_page(page_content))
        
        st.session_state.extracted_pages[page_index] = new_result
    
    st.rerun()

def handle_meta_tag_generation(page_index: int, raw_markdown: str):
    """Generuje meta tagi dla artykuÅ‚u"""
    with st.spinner("Generowanie meta tagÃ³w..."):
        ai_processor = AIProcessor(st.session_state.api_key, st.session_state.model)
        tags = asyncio.run(ai_processor.generate_meta_tags(raw_markdown))
        st.session_state.meta_tags[page_index] = tags
    
    st.rerun()

def handle_seo_generation(page_index: int, raw_markdown: str):
    """Generuje zoptymalizowanÄ… wersjÄ™ artykuÅ‚u"""
    with st.spinner("ğŸš€ Optymalizowanie artykuÅ‚u dla SEO... To moÅ¼e chwilÄ™ potrwaÄ‡."):
        ai_processor = AIProcessor(st.session_state.api_key, st.session_state.model)
        result = asyncio.run(ai_processor.generate_seo_article(raw_markdown))
        st.session_state.seo_articles[page_index] = result
    
    st.rerun()

# ===== GÅÃ“WNA APLIKACJA =====

def main():
    st.set_page_config(
        layout="wide",
        page_title="Redaktor AI - Procesor DokumentÃ³w",
        page_icon="ğŸš€"
    )
    
    st.markdown("""
    <style>
    .page-text-wrapper {
        border: 1px solid #e0e0e0;
        border-radius: 8px;
        padding: 20px;
        background-color: #f9f9f9;
        max-height: 600px;
        overflow-y: auto;
    }
    .error-box {
        background-color: #ffebee;
        border-left: 4px solid #f44336;
        padding: 12px;
        border-radius: 4px;
        margin: 10px 0;
    }
    .stButton button {
        border-radius: 8px;
    }
    h2, h3, h4 {
        margin-top: 1em;
        margin-bottom: 0.5em;
    }
    </style>
    """, unsafe_allow_html=True)
    
    st.title("ğŸš€ Redaktor AI - Interaktywny Procesor DokumentÃ³w")
    
    init_session_state()
    
    if not DOCX_AVAILABLE or not MAMMOTH_AVAILABLE:
        missing = []
        if not DOCX_AVAILABLE:
            missing.append("DOCX (zainstaluj: pip install python-docx)")
        if not MAMMOTH_AVAILABLE:
            missing.append("DOC (zainstaluj: pip install mammoth)")
        
        with st.sidebar:
            with st.expander("âš ï¸ Ograniczona funkcjonalnoÅ›Ä‡", expanded=False):
                st.warning("NiektÃ³re formaty plikÃ³w nie sÄ… dostÄ™pne:")
                for fmt in missing:
                    st.write(f"- {fmt}")
    
    if not st.session_state.api_key:
        st.error("âŒ Brak klucza API OpenAI!")
        st.info("ProszÄ™ skonfiguruj swÃ³j klucz API w Streamlit Secrets.")
        st.stop()
    
    render_sidebar()
    
    if not st.session_state.document:
        if not st.session_state.project_loaded_and_waiting_for_file:
            st.info("ğŸ‘‹ Witaj! Aby rozpoczÄ…Ä‡, wgraj plik (PDF/DOCX/DOC) lub zaÅ‚aduj istniejÄ…cy projekt z panelu bocznego.")
            
            with st.expander("ğŸ“– Jak korzystaÄ‡ z aplikacji?"):
                st.markdown("""
                ### Tryby przetwarzania:
                
                1. **CaÅ‚y dokument** - Przetwarza kaÅ¼dÄ… stronÄ™ osobno, jedno zapytanie na stronÄ™
                2. **Zakres stron** - Przetwarza wybrany zakres stron osobno
                3. **ArtykuÅ‚ wielostronicowy** - ÅÄ…czy wybrane strony i przetwarza jako jeden artykuÅ‚ w jednym zapytaniu
                
                ### ObsÅ‚ugiwane formaty:
                - PDF (z podglÄ…dem i wyciÄ…ganiem grafik)
                - DOCX (Microsoft Word)
                - DOC (starsze pliki Word)
                
                ### Funkcje:
                - Zapisywanie i Å‚adowanie projektÃ³w
                - WyciÄ…ganie grafik ze stron
                - Generowanie meta tagÃ³w SEO
                - **NowoÅ›Ä‡! Optymalizacja artykuÅ‚Ã³w pod kÄ…tem SEO**
                - **Eksport do HTML** - czysty HTML z obsÅ‚ugÄ… list i przypisÃ³w
                - Ponowne przetwarzanie stron z kontekstem
                """)
        return
    
    render_processing_status()
    
    if st.session_state.processing_status == 'in_progress':
        run_ai_processing_loop()
    else:
        render_navigation()
        render_page_view()

if __name__ == "__main__":
    main()
